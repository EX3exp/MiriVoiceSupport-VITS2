{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EX3exp/MiriVoiceSupport-VITS2/blob/main/VITS2_MiriVoice_Support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kys2jeeG3DNp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title 1. Set Up | í™˜ê²½ ì„¤ì¹˜\n",
        "#@markdown Please turn on your GPU. <br> Colab Pro is highly recommended, And  THERE'S NO NEED TO USE A100 - if you're willing to use default config file. (L4 IS ENOUGH)\n",
        "#@markdown <br>ë°˜ë“œì‹œ GPUë¥¼ í™œì„±í™”í•´ ì£¼ì„¸ìš”. <br> Colab Proë¥¼ ì¶”ì²œí•˜ë©°, ê°€ì†ê¸°ëŠ” L4ë¡œ ì„¤ì •í•˜ë©´ ë”± ì•Œë§ìŠµë‹ˆë‹¤. (ë‚´ì¥ëœ config íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ì „ì œ í•˜ì—, A100ì€ êµ³ì´ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.)\n",
        "\n",
        "print(f\"ğŸ”¸ 1. Cloning MiriVoiceSupport-VITS2 Github...\")\n",
        "!git clone https://github.com/EX3exp/MiriVoiceSupport-VITS2.git\n",
        "\n",
        "print(f\"âœ”ï¸ Done!\")\n",
        "\n",
        "!apt-get install espeak\n",
        "\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(f\"ğŸ”¸ 2. Installing Dependencies...\")\n",
        "\n",
        "!pip install tensorflow[and-cuda]==2.16.1\n",
        "!pip install -r /content/MiriVoiceSupport-VITS2/requirements.txt\n",
        "\n",
        "\n",
        "\n",
        "print(f\"âœ”ï¸ Done!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"âœ”ï¸âœ”ï¸âœ”ï¸ Please Restart Session! | ì„¸ì…˜ì„ ë‹¤ì‹œ ì‹œì‘í•´ ì£¼ì„¸ìš”!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nHgS_xYz1H-c"
      },
      "outputs": [],
      "source": [
        "#@title MiriVoice-VITS2 Voicer Making Notebook <br>ë¯¸ë¦¬ë³´ì´ìŠ¤ê°€ ì œê³µí•˜ëŠ” VITS2 í›ˆë ¨ìš© ì½œë ë…¸íŠ¸ë¶ì´ì—ìš”.\n",
        "#@markdown <br>MiriVoice Github â¡ï¸ https://github.com/EX3exp/MiriVoice\n",
        "#@markdown <br><br> Reference | ì°¸ì¡°ìë£Œ : <br> https://arxiv.org/abs/2307.16430 <br> https://github.com/p0p4k/vits2_pytorch\n",
        "\n",
        "#@markdown ğŸ“– [EN] Please select Notebook's language. <br> Messages will be appeared with selected language.\n",
        "#@markdown <br>ğŸ“– [KO] ë…¸íŠ¸ë¶ì˜ ì–¸ì–´ë¥¼ ê³¨ë¼ ì£¼ì„¸ìš”. <br> ì„¤ì •ëœ ì–¸ì–´ë¡œ ë…¸íŠ¸ë¶ì˜ ë©”ì‹œì§€ë“¤ì´ í‘œì‹œë©ë‹ˆë‹¤.\n",
        "language = \"í•œêµ­ì–´\" #@param = [\"English\", \"í•œêµ­ì–´\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyXoGSTNK4s1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 0-1. Mount Google Drive | êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "dir_paths = [\"/content/drive/MyDrive/MiriVoice/VITS2/train/dataset\", \"/content/drive/MyDrive/MiriVoice/VITS2/voicer\", \"/content/drive/MyDrive/MiriVoice/VITS2/checkpoints\"]\n",
        "\n",
        "train_main_path = \"/content/train\"\n",
        "\n",
        "if (language == \"English\"):\n",
        "    print(f\"âœ”ï¸ Generated Directory in colab runtime -- {train_main_path}\")\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(f\"âœ”ï¸ ì½”ë© ëŸ°íƒ€ì„ ë‚´ì— í´ë”ë¥¼ ìƒì„±í–ˆì–´ìš” -- {train_main_path}\")\n",
        "\n",
        "os.makedirs(\"dir_path\", exist_ok=True)\n",
        "for dir_path in dir_paths:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    if (language == \"English\"):\n",
        "        print(f\"âœ”ï¸ Generated Directory in google drive -- {dir_path}\")\n",
        "    elif (language == \"í•œêµ­ì–´\"):\n",
        "        print(f\"âœ”ï¸ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— í´ë”ë¥¼ ìƒì„±í–ˆì–´ìš” -- {dir_path}\")\n",
        "\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ”ï¸ [Torch cuda is available] Current Torch Version Is: {torch.__version__}\")\n",
        "\n",
        "else :\n",
        "    print(f\"â— [Torch cuda is Not Available] -- Please Enable GPU! | GPUë¥¼ í™œì„±í™”í•´ ì£¼ì„¸ìš”! \")\n",
        "    exit()\n",
        "\n",
        "print()\n",
        "if (language == \"English\"):\n",
        "    print(f\"ğŸ§ Please make sure YOUR ğŸ—‚ï¸dataset.zip to be in your Google Drive's ğŸ“‚MiriVoice/VITS2/train/dataset. \")\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(f\"ğŸ§ êµ¬ê¸€ ë“œë¼ì´ë¸Œì˜ ğŸ“‚MiriVoice/VITS2/train/dataset ì— ğŸ—‚ï¸dataset.zipì´ ë“¤ì–´ê°€ ìˆëŠ”ì§€ ì˜ í™•ì¸í•´ ì£¼ì„¸ìš”. \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y7kZgPzblkfr"
      },
      "outputs": [],
      "source": [
        "#@title 0-2. Choose Finetuning Model | íŒŒì¸íŠœë‹ ëª¨ë¸\n",
        "#@markdown âš ï¸If you want to resume training with your own checkpoints or do not want finetuning, please SKIP this cell. <br> âš ï¸ë³´ìœ í•œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ ì´ì–´ì„œ í›ˆë ¨ì„ ì§„í–‰í•˜ë ¤ í•˜ê±°ë‚˜, íŒŒì¸íŠœë‹ì„ í•˜ì§€ ì•Šì„ ê³„íšì´ë¼ë©´, ì´ ì…€ì„ ì‹¤í–‰í•  í•„ìš”ê°€ ì—†ì–´ìš”.\n",
        "#@markdown <br>If your voice pitch is low, please choose Rivo, otherwise Miri.\n",
        "#@markdown <br>ë³¸ì¸ì˜ ëª©ì†Œë¦¬ í†¤ì´ ë‚®ë‹¤ë©´ Rivoë¥¼, ì•„ë‹ˆë¼ë©´ Mirië¥¼ ê³¨ë¼ ì£¼ì„¸ìš”.\n",
        "import os\n",
        "fintune_model = \"Miri\" #@param = [\"Miri\", \"Rivo\"]\n",
        "\n",
        "!apt-get install aria2\n",
        "\n",
        "\n",
        "if fintune_model == \"Miri\":\n",
        "    ! aria2c -x 16 \"https://github.com/EX3exp/MiriVoiceSupport-VITS2/releases/latest/download/Base_Miri.zip\"\n",
        "    !unzip -qq '/content/Base_Miri.zip' -d '/content/drive/MyDrive/MiriVoice/VITS2/checkpoints'\n",
        "elif fintune_model == \"Rivo\":\n",
        "    ! aria2c -x 16 \"https://github.com/EX3exp/MiriVoiceSupport-VITS2/releases/latest/download/Base_Rivo.zip\"\n",
        "    !unzip -qq '/content/Base_Rivo.zip' -d '/content/drive/MyDrive/MiriVoice/VITS2/checkpoints'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ESyRT54s5k8",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "dataset_zip_name = \"dataset.zip\" #@param\n",
        "dataset_zip_path = os.path.join(dir_paths[0], dataset_zip_name)\n",
        "\n",
        "if (language == \"English\"):\n",
        "    print(f\"ğŸ”¸ 1. Unzipping dataset ({dataset_zip_path})...\")\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(f\"ğŸ”¸ 1. ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ ì¤‘ ({dataset_zip_path})...\")\n",
        "!unzip -qq '{dataset_zip_path}' -d '{train_main_path}'\n",
        "\n",
        "if (language == \"English\"):\n",
        "    print(f\"âœ”ï¸ {dataset_zip_name} unzipped in: {train_main_path} \")\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(f\"âœ”ï¸ {dataset_zip_name}ì„(ë¥¼) {train_main_path}ì— ì••ì¶• í•´ì œí–ˆì–´ìš”. \")\n",
        "train_filelist_path = \"\"\n",
        "val_filelist_path = \"\"\n",
        "\n",
        "config_file_dir = \"/content/MiriVoiceSupport-VITS2/configs/\"\n",
        "config_file = \"config-mirivoice-colab-fintune-v2.json\" #@param [\"config-mirivoice-colab-fintune-v2.json\", \"config-mirivoice-colab-no_fintune.json\", \"config-mirivoice-colab-fintune.json\", \"config-mirivoice-colab-enarctic-fintune-v2.json\", \"config-mirivoice-colab-enarctic-no_fintune.json\"]\n",
        "config_path = f\"{config_file_dir}{config_file}\"\n",
        "\n",
        "#@title 2. Set Files | íŒŒì¼ ì§€ì •\n",
        "\n",
        "if (language == \"English\"):\n",
        "    print(f\"ğŸ”¸ 2. Building monotonic align...\")\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(f\"ğŸ”¸ 2. monotonic align ë¹Œë“œ ì¤‘...\")\n",
        "os.chdir('/content/MiriVoiceSupport-VITS2/monotonic_align')\n",
        "os.makedirs('/content/MiriVoiceSupport-VITS2/monotonic_align/monotonic_align', exist_ok=True)\n",
        "!python setup.py build_ext --inplace\n",
        "\n",
        "if (language == \"English\"):\n",
        "    print(f\"âœ”ï¸ Done!\")\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(f\"âœ”ï¸ ì™„ë£Œ! \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgQuBTNs0xue",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Audio Preprocess | ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "folder_tr_path = '/content/train/train'\n",
        "folder_vl_path = '/content/train/validation'\n",
        "\n",
        "length = len(os.listdir(folder_tr_path))\n",
        "\n",
        "print(f\"[   Train set   ]  total: {length-1} downsampling to 44100kHZ ... \")\n",
        "for i, filename in enumerate(os.listdir(folder_tr_path)):\n",
        "    if filename.endswith('.wav'):\n",
        "        file_path = os.path.join(folder_tr_path, filename)\n",
        "\n",
        "        y, sr = librosa.load(file_path, sr=None)\n",
        "        y = librosa.util.normalize(y)\n",
        "        y_resampled = librosa.resample(y, orig_sr=sr, target_sr=44100)\n",
        "\n",
        "\n",
        "        output_file_path = os.path.join(folder_tr_path, filename)\n",
        "\n",
        "        sf.write(output_file_path, y_resampled, 44100)\n",
        "        print(\"*\", end=\"\")\n",
        "\n",
        "print()\n",
        "length = len(os.listdir(folder_vl_path))\n",
        "print(f\"[Validation set]  total: {length-1} downsampling to 44100kHZ\")\n",
        "for i, filename in enumerate(os.listdir(folder_vl_path)):\n",
        "    if filename.endswith('.wav'):\n",
        "        file_path = os.path.join(folder_vl_path, filename)\n",
        "\n",
        "        y, sr = librosa.load(file_path, sr=None)\n",
        "        y = librosa.util.normalize(y)\n",
        "        y_resampled = librosa.resample(y, orig_sr=sr, target_sr=44100)\n",
        "\n",
        "        output_file_path = os.path.join(folder_vl_path, filename)\n",
        "\n",
        "        sf.write(output_file_path, y_resampled, 44100)\n",
        "        print(\"*\", end=\"\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iFQIAhw3TY1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Tensorboard | í…ì„œë³´ë“œ\n",
        "\n",
        "if (language == \"English\"):\n",
        "    print(\"--- TensorBoard ---\")\n",
        "\n",
        "    print()\n",
        "    print(\"Please Run cell right below... \")\n",
        "    print(\"All you have to do is watching TensorBoard at here, And stop training in proper time. (to stop training, press stop button in left of below cell.)\")\n",
        "    print()\n",
        "    print(f\"ğŸ§ Please check scalars' â‡ï¸mel_loss, â‡ï¸kl_loss during training.\")\n",
        "    print(f\"ğŸ§ You might can stop training when: \")\n",
        "    print(f\"\\t- mel_loss is smaller than 15\")\n",
        "    print(f\"\\t- kl_loss is almost 1 or 2\")\n",
        "\n",
        "elif (language == \"í•œêµ­ì–´\"):\n",
        "    print(\"--- í…ì„œë³´ë“œ ---\")\n",
        "\n",
        "    print()\n",
        "    print(\"ì´ì œ ì´ ì…€ ì•„ë˜ì˜ ì…€ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”... \")\n",
        "    print(\"ì—¬ê¸°ì„œ í…ì„œë³´ë“œë¥¼ ê³„ì† ì§€ì¼œë´ ì£¼ì„¸ìš”. ì ì •í•œ ë•Œì— í•˜ë‹¨ ì…€ ì™¼ìª½ì˜ ì •ì§€ ë²„íŠ¼ì„ ëˆŒëŸ¬ í›ˆë ¨ì„ ì¤‘ë‹¨í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\")\n",
        "    print()\n",
        "    print(f\"ğŸ§ í›ˆë ¨ì´ ì´ë£¨ì–´ì§€ëŠ” ë™ì•ˆ, scalarsì˜ â‡ï¸mel_loss, â‡ï¸kl_loss ì— ì£¼ëª©í•˜ì„¸ìš”.\")\n",
        "    print(f\"ğŸ§ í›ˆë ¨ì„ ë©ˆì¶°ë„ ë  ë•Œ: \")\n",
        "    print(f\"\\t- mel_lossê°€ 15 ì´í•˜ì¼ ë•Œ\")\n",
        "    print(f\"\\t- kl_lossê°€ 1~2 ê°€ëŸ‰ì¼ ë•Œ\")\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '{train_main_path}/logs'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiPG-bd1636M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training | í›ˆë ¨\n",
        "import os\n",
        "os.chdir(train_main_path)\n",
        "!python /content/MiriVoiceSupport-VITS2/train_ms.py -c '{config_path}' -m mirivoice-vits2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}